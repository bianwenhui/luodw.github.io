<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="kafka," />





  <link rel="alternate" href="/atom.xml" title="罗道文的私房菜" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="最近在kafka的代码，着实有点吃力，因为这是我第一次看java类代码，没有当时看redis(c语言)和NSQ(golang语言)那种享受，第一是kafka代码量非常大，第二是kafka代码封装较多。我们知道数据库或者文件戏系统的客户端一般都是当需要获取数据时，发送请求和等待回复。然而消息队列的客户端比上述复杂，例如，kafka一般是用在分布式架构下，因此kafka server都不止一台，所以k">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka源码分析之Producer">
<meta property="og:url" content="http://luodw.cc/2017/05/02/kafka02/index.html">
<meta property="og:site_name" content="罗道文的私房菜">
<meta property="og:description" content="最近在kafka的代码，着实有点吃力，因为这是我第一次看java类代码，没有当时看redis(c语言)和NSQ(golang语言)那种享受，第一是kafka代码量非常大，第二是kafka代码封装较多。我们知道数据库或者文件戏系统的客户端一般都是当需要获取数据时，发送请求和等待回复。然而消息队列的客户端比上述复杂，例如，kafka一般是用在分布式架构下，因此kafka server都不止一台，所以k">
<meta property="og:updated_time" content="2017-05-06T05:12:09.055Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kafka源码分析之Producer">
<meta name="twitter:description" content="最近在kafka的代码，着实有点吃力，因为这是我第一次看java类代码，没有当时看redis(c语言)和NSQ(golang语言)那种享受，第一是kafka代码量非常大，第二是kafka代码封装较多。我们知道数据库或者文件戏系统的客户端一般都是当需要获取数据时，发送请求和等待回复。然而消息队列的客户端比上述复杂，例如，kafka一般是用在分布式架构下，因此kafka server都不止一台，所以k">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"always"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://luodw.cc/2017/05/02/kafka02/"/>


  <title> kafka源码分析之Producer | 罗道文的私房菜 </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?c8bfd43d39ee97fe670b76fe06d38c03";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">罗道文的私房菜</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">分享知识，分享快乐</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-2017-reading">
          <a href="/2017-reading" rel="section">
            
            阅读
          </a>
        </li>
      
        
        <li class="menu-item menu-item-bookmark">
          <a href="/bookmark" rel="section">
            
            书签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'chcHaQRahdwMUNbzMpw5','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                kafka源码分析之Producer
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-05-02T11:26:53+08:00" content="2017-05-02">
              2017-05-02
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index">
                    <span itemprop="name">kafka</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/05/02/kafka02/" class="leancloud_visitors" data-flag-title="kafka源码分析之Producer">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>最近在kafka的代码，着实有点吃力，因为这是我第一次看java类代码，没有当时看redis(c语言)和NSQ(golang语言)那种享受，第一是kafka代码量非常大，第二是kafka代码封装较多。我们知道数据库或者文件戏系统的客户端一般都是当需要获取数据时，发送请求和等待回复。然而消息队列的客户端比上述复杂，例如，kafka一般是用在分布式架构下，因此kafka server都不止一台，所以kafka消息队列的Producer就需要一个IO多路复用进行每个连接是否可写以及可读；而且kafka的Consumer是基于pull策略，因此需要每隔一段时间向kafka server发送fetch request等等。</p>
<p>kafka server的整体架构比较容易看懂，因为服务器的架构大体是IO多路复用，事件分发，事件处理等等，但是kafka server的其他细节，包括日志持久化，日志复制以及选主等等则不是一天两天能看懂的，因此我看代码的策略就是在把kafka server的整体大体架构看懂之后，先看Producer和Consumer，从简单的开始，可以先把一些基础的知识点过一遍，例如Java NIO以及Java Concurrent包。而Producer比Consumer稍微更简单些，我就从Producer开始看了。</p>
<p>我看的客户端是Java(Kafka源码自带)，也是Kafka最新版本推荐的客户端。本文大概按如下组织:</p>
<ol>
<li>Kafka Producer使用介绍；</li>
<li>Kafka Producer运行原理；</li>
<li>Kafka Producer运行过程；</li>
<li>总结；</li>
</ol>
<p>【版权声明】博客内容由罗道文的私房菜拥有版权，允许转载，但请标明原文链接<a href="http://luodw.cc/2017/05/02/kafka02/#more">http://luodw.cc/2017/05/02/kafka02/#more</a></p>
<h1>Kafka Producer使用介绍</h1>
<hr>
<p>在上篇文章中，给出了一个Java客户端简单的使用示例，可以参考<a href="http://luodw.cc/2017/04/24/kafka01/">kafka源码分析之概述</a>。Java客户端默认使用的异步发送，即Producer不断将消息发送到一个队列中，然后一个后台线程不断从队列中获取消息，最后封装成请求发送给kafka server。对于异步模式，Producer.send函数参数提供一个参数callback，即当请求完成时执行的回调函数；一般调用情况如下:
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"> ProducerRecord&lt;<span class="keyword">byte</span>[],<span class="keyword">byte</span>[]&gt; record = <span class="keyword">new</span> ProducerRecord&lt;<span class="keyword">byte</span>[],<span class="keyword">byte</span>[]&gt;(<span class="string">"the-topic"</span>, key, value);</div><div class="line"> producer.send(myRecord,</div><div class="line">        <span class="keyword">new</span> Callback() &#123;</div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception e)</span> </span>&#123;</div><div class="line">                <span class="keyword">if</span>(e != <span class="keyword">null</span>) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125; <span class="keyword">else</span> &#123;</div><div class="line">                    System.out.println(<span class="string">"The offset of the record we just sent is: "</span> + metadata.offset());</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;);</div><div class="line">&#125;</div><div class="line">`</div></pre></td></tr></table></figure></p>
<p>这段代码实例化一个ProducerRecord，然后通过producer.send函数发送，当发送成功并且得到kafka server的ack时，执行回调函数Callback。这个回调函数接收这条记录的元数据，包括偏移量，事件戳，checksum，序列后key和value的长度以及分区。</p>
<p>当然，Java客户端也可以模拟同步阻塞调用，可以采用如下方式：
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">byte</span>[] key = <span class="string">"key"</span>.getBytes();</div><div class="line"><span class="keyword">byte</span>[] value = <span class="string">"value"</span>.getBytes();</div><div class="line">ProducerRecord&lt;<span class="keyword">byte</span>[],<span class="keyword">byte</span>[]&gt; record = <span class="keyword">new</span> ProducerRecord&lt;<span class="keyword">byte</span>[],<span class="keyword">byte</span>[]&gt;(<span class="string">"my-topic"</span>, key, value)</div><div class="line">producer.send(record).get();</div></pre></td></tr></table></figure></p>
<p>因为Producer.send方法返回值是java.util.concurrent.Future，所以Future.get()方法会阻塞直到kafka server的响应返回。</p>
<h1>Kafka Producer运行原理</h1>
<hr>
<p>之前有提到过，Kafka Producer采取异步的方式发送消息。当实例化一个Kafka Producer，同时会开启一个IO线程sender，该线程不断读取队列中的消息，然后通过Selector将数据发送给Kafka Server。用户调用Producer.send方法发送消息时，所执行的步骤如下：</p>
<ol>
<li>与topic相关的broker建立连接，更新元数据(包括当前producer相关的topic,partition,broker等等信息)，后续分析分析元数据时再细说。</li>
<li>根据key决定当前消息将发送给当前topic的哪个分区。如果用户给出key，则对该key进行哈希求余，得到分区号；如果用户没有提供key，则采用round-robin方式决定分区。</li>
<li>将该消息添加到RecordAccumulator中对应的队列中，而RecordAccumulator内包含若干双端队列列表，每个topic的每个partition都对应着一个双端队列列表，每个列表含有若干RecordBatch，而每个RecordBatch可以存储若干条消息。</li>
</ol>
<p>上述就是producer.send方法所执行的过程，当将数据放到队列后，即可返回执行下一次的producer.send；　因为异步，执行速度非常快；　接下来，当队列中有了数据之后，即可把视角切换到IO线程sender，sender线程处于一个while循环中，不断获取消息发送，执行过程如下:</p>
<ol>
<li>将RecordAccumulator中消息按broker进行重新分类，因为kafka把发往同一个broker的消息整合在一个request中，因此，如果有四个broker，则会产生size=4的Map&lt;Integer, List&lt;RecordBatch&gt;&gt;。</li>
<li>将每个broker对应的List&lt;RecordBatch&gt;序列化后存储再ByteBuffer，并将这个ByteBuffer与broker对应的socketChannel绑定，最后注册到selector等待发送。</li>
<li>在下一次selector超时时，即可读取Kafka Server返回的response，并执行相应的回调函数；</li>
</ol>
<p>当然，上述步骤看起来非常的简单，但是体现在代码上却是非常的复杂。下面跟着代码来看看。</p>
<h1>Kafka Producer运行过程</h1>
<hr>
<p>这里不可能把所有代码都粘贴进来，因为代码量太大了，所以把Producer执行的大致流程以及不容易看不懂的地方记录下。Producer除了发送消息，还时不时的需要更新metadata，例如一开始时需要连接到broker上，如果Producer要把消息发送到新的topic上，则这时也需要更新metadata，因为metadata没有关于这个topic的partition和broker信息。这里屏蔽更新metadata的细节，专注与消息的发送和接受，之后再讲metadata的更新。</p>
<h2>Producer发送消息</h2>
<p>由测试例子可知，要发送消息，首先要实例化一个Producer实例，代码如下，只保留最重要的信息。
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="title">KafkaProducer</span><span class="params">(ProducerConfig config, Serializer&lt;K&gt; keySerializer, Serializer&lt;V&gt; valueSerializer)</span> </span>&#123;</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    log.trace(<span class="string">"Starting the Kafka producer"</span>);</div><div class="line">    <span class="comment">// 获取用户传入的参数</span></div><div class="line">    Map&lt;String, Object&gt; userProvidedConfigs = config.originals();</div><div class="line">    <span class="keyword">this</span>.producerConfig = config;</div><div class="line">    <span class="keyword">this</span>.time = Time.SYSTEM;</div><div class="line"></div><div class="line">    clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG);</div><div class="line">    <span class="keyword">if</span> (clientId.length() &lt;= <span class="number">0</span>)</div><div class="line">        clientId = <span class="string">"producer-"</span> + PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement();</div><div class="line">    <span class="comment">/*.......*/</span></div><div class="line">    <span class="comment">// 设置分区类，支持自定义分区策略，默认使用的DefaultPartitioner</span></div><div class="line">    <span class="keyword">this</span>.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner.class);</div><div class="line">    <span class="comment">// load interceptors and make sure they get clientId</span></div><div class="line">    userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId);</div><div class="line">    <span class="comment">//　与该Producer相关的元数据</span></div><div class="line">    <span class="keyword">this</span>.metadata = <span class="keyword">new</span> Metadata(retryBackoffMs, config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG), <span class="keyword">true</span>, clusterResourceListeners);</div><div class="line">    <span class="comment">// 每个请求的最大字节数</span></div><div class="line">    <span class="keyword">this</span>.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);</div><div class="line">    <span class="comment">//　Producer异步队列内存的最大值</span></div><div class="line">    <span class="keyword">this</span>.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG);</div><div class="line">    <span class="comment">//　压缩类型</span></div><div class="line">    <span class="keyword">this</span>.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG));</div><div class="line">    <span class="comment">//　缓存每个topic-partition对应消息队列集合</span></div><div class="line">    <span class="keyword">this</span>.accumulator = <span class="keyword">new</span> RecordAccumulator(config.getInt(ProducerConfig.BATCH_SIZE_CONFIG),</div><div class="line">            <span class="keyword">this</span>.totalMemorySize,</div><div class="line">            <span class="keyword">this</span>.compressionType,</div><div class="line">            config.getLong(ProducerConfig.LINGER_MS_CONFIG),</div><div class="line">            retryBackoffMs,</div><div class="line">            metrics,</div><div class="line">            time);</div><div class="line">    <span class="comment">//　用户提供的broker地址</span></div><div class="line">    List&lt;InetSocketAddress&gt; addresses = ClientUtils.parseAndValidateAddresses(config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG));</div><div class="line">    <span class="keyword">this</span>.metadata.update(Cluster.bootstrap(addresses), time.milliseconds());</div><div class="line">    ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config.values());</div><div class="line">    <span class="comment">//　kafka封装selector，而NetworkClient则是处理selector返回的结果</span></div><div class="line">    NetworkClient client = <span class="keyword">new</span> NetworkClient(</div><div class="line">            <span class="keyword">new</span> Selector(config.getLong(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG), <span class="keyword">this</span>.metrics, time, <span class="string">"producer"</span>, channelBuilder),</div><div class="line">            <span class="keyword">this</span>.metadata,</div><div class="line">            clientId,</div><div class="line">            config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION),</div><div class="line">            config.getLong(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG),</div><div class="line">            config.getInt(ProducerConfig.SEND_BUFFER_CONFIG),</div><div class="line">            config.getInt(ProducerConfig.RECEIVE_BUFFER_CONFIG),</div><div class="line">            <span class="keyword">this</span>.requestTimeoutMs,</div><div class="line">            time,</div><div class="line">            <span class="keyword">true</span>);</div><div class="line">    <span class="comment">//　异步线程类</span></div><div class="line">    <span class="keyword">this</span>.sender = <span class="keyword">new</span> Sender(client,</div><div class="line">            <span class="keyword">this</span>.metadata,</div><div class="line">            <span class="keyword">this</span>.accumulator,</div><div class="line">            config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION) == <span class="number">1</span>,</div><div class="line">            config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG),</div><div class="line">            (<span class="keyword">short</span>) parseAcks(config.getString(ProducerConfig.ACKS_CONFIG)),</div><div class="line">            config.getInt(ProducerConfig.RETRIES_CONFIG),</div><div class="line">            <span class="keyword">this</span>.metrics,</div><div class="line">            Time.SYSTEM,</div><div class="line">            <span class="keyword">this</span>.requestTimeoutMs);</div><div class="line">    String ioThreadName = <span class="string">"kafka-producer-network-thread"</span> + (clientId.length() &gt; <span class="number">0</span> ? <span class="string">" | "</span> + clientId : <span class="string">""</span>);</div><div class="line">    <span class="keyword">this</span>.ioThread = <span class="keyword">new</span> KafkaThread(ioThreadName, <span class="keyword">this</span>.sender, <span class="keyword">true</span>);</div><div class="line">    <span class="keyword">this</span>.ioThread.start();<span class="comment">//开启异步线程类</span></div><div class="line"></div><div class="line">    log.debug(<span class="string">"Kafka producer started"</span>);</div><div class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</div><div class="line">        <span class="comment">/*.....*/</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>由代码可知，在实例化KafkaProducer过程中，首先将用户输入的属性转化为ProducerConfig对象，利用该配置对象实例化整个KafkaProducer所需要的资源，例如分区类，消息缓存队列以及异步线程类等等。由代码还可以知：</p>
<ol>
<li>分区类可以自己定义，即自己定义每条消息发送至哪个分区，如果用户没有自定义，则使用默认分区类DefaultPartitioner；</li>
<li>缓存类accumulator，用户可以定义缓存类可以使用的内存大小(ProducerConfig.BUFFER_MEMORY_CONFIG)，每个RecordBatch大小(config.getInt(ProducerConfig.BATCH_SIZE_CONFIG)，　producer汇集时长为linger_ms之间的消息发送，消息重传的时间间隔(retryBackoffMs)；</li>
<li>不需要给出所有的broker地址，因为Producer会定期更新metadata，因此会自动获取所有broker地址；</li>
<li>负责网络发送的客户端NetworkClient，用户可以配置的信息为连接最长闲置时间，每个连接正在发送的最大消息数，重连接间隔时间，发送和接收缓存大小以及请求超时时长；</li>
<li>对于异步线程类，用户可以配置是否保证消息的顺序性，单次请求最大值，ack配置，请求重传配置等等；</li>
</ol>
<p>在KafkaProducer实例化成功之后，接下来即可通过send方法发送消息，代码如下
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</div><div class="line">TopicPartition tp = <span class="keyword">null</span>;</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// waitOnMetadata方法用于保证在发送消息之前，已经连上topic相关的broker以及更新metadata</span></div><div class="line">    ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</div><div class="line">    <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</div><div class="line">    Cluster cluster = clusterAndWaitTime.cluster;</div><div class="line">    <span class="keyword">byte</span>[] serializedKey;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        serializedKey = keySerializer.serialize(record.topic(), record.key());</div><div class="line">    &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</div><div class="line">        <span class="comment">/*.....*/</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">byte</span>[] serializedValue;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        serializedValue = valueSerializer.serialize(record.topic(), record.value());</div><div class="line">    &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</div><div class="line">        <span class="comment">/*....*/</span></div><div class="line">    &#125;</div><div class="line">    <span class="comment">//　设置该消息的分区号</span></div><div class="line">    <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</div><div class="line">    <span class="keyword">int</span> serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);</div><div class="line">    ensureValidRecordSize(serializedSize);</div><div class="line">    tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</div><div class="line">    <span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp();</div><div class="line">    <span class="comment">// 将消息添加到accumulator缓存中</span></div><div class="line">    RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);</div><div class="line">    <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</div><div class="line">        log.trace(<span class="string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);</div><div class="line">        <span class="comment">// 如果RecordBatch满了，则唤醒IO线程发送一次消息；　</span></div><div class="line">        <span class="keyword">this</span>.sender.wakeup();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> result.future;</div><div class="line">    <span class="comment">// handling exceptions and record the errors;</span></div><div class="line">    <span class="comment">// for API exceptions return them in the future,</span></div><div class="line">    <span class="comment">// for other exceptions throw directly</span></div><div class="line">&#125; <span class="keyword">catch</span> (ApiException e) &#123;</div><div class="line">    <span class="comment">/*.....*/</span></div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在这个函数中先是根据消息计算出该消息所对应的分区，然后调用accumulator.append追加对应的消息列表中。消息队列时一个map，键为TopicPartition，值为一个RecordBatch列表，即一个topic分区对应着消息列表中。</p>
<p>再accumulator.append方法中先是根据TopicPartition找到对应的列表(如果没有，则新建一个)，然后取出列表最后一个RecordBatch，最后调用RecordBatch.tryAppend方法，下面看下
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> FutureRecordMetadata <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line"><span class="keyword">if</span> (!recordsBuilder.hasRoomFor(key, value)) &#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="keyword">long</span> checksum = <span class="keyword">this</span>.recordsBuilder.append(timestamp, key, value);</div><div class="line">    <span class="keyword">this</span>.maxRecordSize = Math.max(<span class="keyword">this</span>.maxRecordSize, Record.recordSize(key, value));</div><div class="line">    <span class="keyword">this</span>.lastAppendTime = now;</div><div class="line">    FutureRecordMetadata future = <span class="keyword">new</span> FutureRecordMetadata(<span class="keyword">this</span>.produceFuture, <span class="keyword">this</span>.recordCount,</div><div class="line">                                                            timestamp, checksum,</div><div class="line">                                                            key == <span class="keyword">null</span> ? -<span class="number">1</span> : key.length,</div><div class="line">                                                            value == <span class="keyword">null</span> ? -<span class="number">1</span> : value.length);</div><div class="line">    <span class="keyword">if</span> (callback != <span class="keyword">null</span>)</div><div class="line">        thunks.add(<span class="keyword">new</span> Thunk(callback, future));</div><div class="line">    <span class="keyword">this</span>.recordCount++;</div><div class="line">    <span class="keyword">return</span> future;</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>由代码可知，该函数最后调用的时this.recordsBuilder.append方法添加，那么这个recordBuilder是什么了？append是把消息追加到哪了？我第一次看代码在这懵了。</p>
<p>同过查看RecoredBatch类定义可知这个recordsBuilder为MemoryRecordsBuilder，那我们接下来就可以来看下MemoryRecordsBuilder.append方法将消息添加到哪了
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">append</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> appendWithOffset(lastOffset &lt; <span class="number">0</span> ? baseOffset : lastOffset + <span class="number">1</span>, timestamp, key, value);</div><div class="line">&#125;</div><div class="line"><span class="comment">/*----------------------------------------------------------------------------------------------*/</span></div><div class="line"><span class="comment">//appendStream为封装ByteBuffer的数据流</span></div><div class="line">bufferStream = <span class="keyword">new</span> ByteBufferOutputStream(buffer);</div><div class="line">appendStream = wrapForOutput(bufferStream, compressionType, magic, COMPRESSION_DEFAULT_BUFFER_SIZE);</div><div class="line"><span class="comment">/*--------------------------------------------------------------------------------------------------*/</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">appendWithOffset</span><span class="params">(<span class="keyword">long</span> offset, <span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value)</span> </span>&#123;</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">if</span> (lastOffset &gt;= <span class="number">0</span> &amp;&amp; offset &lt;= lastOffset)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(String.format(<span class="string">"Illegal offset %s following previous offset %s (Offsets must increase monotonically)."</span>, offset, lastOffset));</div><div class="line"></div><div class="line">    <span class="keyword">int</span> size = Record.recordSize(magic, key, value);</div><div class="line">    LogEntry.writeHeader(appendStream, toInnerOffset(offset), size);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (timestampType == TimestampType.LOG_APPEND_TIME)</div><div class="line">        timestamp = logAppendTime;</div><div class="line">    <span class="keyword">long</span> crc = Record.write(appendStream, magic, timestamp, key, value, CompressionType.NONE, timestampType);</div><div class="line">    recordWritten(offset, timestamp, size + Records.LOG_OVERHEAD);</div><div class="line">    <span class="keyword">return</span> crc;</div><div class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"I/O exception when writing to the append stream, closing"</span>, e);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>首先我们需要知道每个RecordBatch都对应一个ByteBuffer和MemoryRecordsBuilder，而MemoryRecordsBuilder的作用就是将每条消息追加到ByteBuffer中。上述代码可知，ByteBuffer被封装成DataOutputStream，<em>LogEntry.writeHeader</em>和<em>Record.write</em>方法即执行把消息头和消息体追加到ByteBuffer当中。</p>
<blockquote>
<p>这里先做个小结，每个KafkaProducer都有一个消息缓存类accumulator，这个缓存类有一个map存储TopicPartiton--&gt;List&lt;RecordBatch&gt;键值对。用户每次发送消息都是先添加到该消息对应TopicPartition的RecordBatch中。而RecordBatch中有一个大小限制的ByteBuffer，存储用户发送的消息。</p>
</blockquote>
<h2>sender线程发送请求</h2>
<p>等消息添加到RecordBatch中之后，接下来可以把视角切换到sender线程。因为sender是一个线程类，我们直接可以定位到该类的run方法
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">while</span> (running) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            run(time.milliseconds());</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            log.error(<span class="string">"Uncaught error in kafka producer I/O thread: "</span>, e);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/*............................................*/</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    Cluster cluster = metadata.fetch();</div><div class="line">    <span class="comment">// get the list of partitions with data ready to send</span></div><div class="line">    RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</div><div class="line">        <span class="comment">//如果还不确定某些topic的leader，则需要更新metadata</span></div><div class="line">    <span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</div><div class="line">        <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</div><div class="line">            <span class="keyword">this</span>.metadata.add(topic);</div><div class="line">        <span class="keyword">this</span>.metadata.requestUpdate();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// remove any nodes we aren't ready to send to</span></div><div class="line">    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</div><div class="line">    <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</div><div class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</div><div class="line">        Node node = iter.next();</div><div class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;</div><div class="line">            iter.remove();</div><div class="line">            notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// create produce requests</span></div><div class="line">    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster,</div><div class="line">                                                                        result.readyNodes,</div><div class="line">                                                                        <span class="keyword">this</span>.maxRequestSize,</div><div class="line">                                                                        now);</div><div class="line"></div><div class="line">    sendProduceRequests(batches, now);</div><div class="line"></div><div class="line">    <span class="comment">//　调用selector发送消息</span></div><div class="line">    <span class="keyword">this</span>.client.poll(pollTimeout, now);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>sender线程处在一个while循环中，不停的从accumulator获取准备好的消息，然后发送。上述run方法最重要步骤有</p>
<p>首先，accumulator.drain函数将TopicPartition--&gt;list&lt;RecordBatch&gt;转换为broker--&gt;list&lt;RecordBatch&gt;，即把消息按broker分类，发往每个broker的消息封装成一次请求。例如如果有两个topic（t1和t2），每个topic都有三个分区(t1p1 t1p2 t1p3 t2p1 t2p2 t2p3)，以及三个broker（b1 b2 b3），分别对应一个分区。那么t1p1和t2p1的数据都将发送到b1中，t1p2和t2p2的数据都将发送到b2中，t1p3和t2p3的数据都将发送到b3中。</p>
<p>接着调用sendProduceRequests函数，这个函数本质上做的事就是把socketChannel和ByteBuffer绑定起来。但是Kafka做了封装，因为这个函数最主要就是把kafkaChannel和每个broker上的list&lt;RecordBatch&gt;绑定起来。这样当selector返回，kafkaChannel为可写，就可以把list&lt;RecordBatch&gt;发送到对应的broker上。</p>
<p>最后this.client.poll(pollTimeout, now)执行selector.poll函数执行读写操作以及调用response的回调函数。我们先来看下sendProduceRequests函数
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequests</span><span class="params">(Map&lt;Integer, List&lt;RecordBatch&gt;&gt; collated, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    <span class="keyword">for</span> (Map.Entry&lt;Integer, List&lt;RecordBatch&gt;&gt; entry : collated.entrySet())</div><div class="line">        sendProduceRequest(now, entry.getKey(), acks, requestTimeout, entry.getValue());</div><div class="line">&#125;<span class="comment">//分别处理发往每个broker上的消息</span></div><div class="line"><span class="comment">/*..................................................................................................*/</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;RecordBatch&gt; batches)</span> </span>&#123;</div><div class="line">    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</div><div class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;&gt;(batches.size());</div><div class="line">    <span class="keyword">for</span> (RecordBatch batch : batches) &#123;</div><div class="line">        TopicPartition tp = batch.topicPartition;</div><div class="line">        <span class="comment">//batch.records()返回MemoryRecords</span></div><div class="line">        produceRecordsByPartition.put(tp, batch.records());</div><div class="line">        recordsByPartition.put(tp, batch);</div><div class="line">    &#125;<span class="comment">//将发往某个broker上消息按TopicPartition进行归类</span></div><div class="line"></div><div class="line">    ProduceRequest.Builder requestBuilder =</div><div class="line">            <span class="keyword">new</span> ProduceRequest.Builder(acks, timeout, produceRecordsByPartition);</div><div class="line">    RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</div><div class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</div><div class="line">        &#125;</div><div class="line">    &#125;;</div><div class="line"></div><div class="line">    String nodeId = Integer.toString(destination);</div><div class="line">    <span class="comment">//实例化一个ClientRequest，这个Request时发往某个broker,包含大于等于１个TopicPartition</span></div><div class="line">    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != <span class="number">0</span>, callback);</div><div class="line">    <span class="comment">//　调用NetworkClient做进一步处理</span></div><div class="line">    client.send(clientRequest, now);</div><div class="line">    log.trace(<span class="string">"Sent produce request to &#123;&#125;: &#123;&#125;"</span>, nodeId, requestBuilder);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>由上可知传递给requtestBuilder的参数produceRecordsByPartition已经时Map&lt;TopicPartition, MemoryRecords&gt;。MemoryRecords对象最重要的成员变量为ByteBuffer，保存该RecordBatch内的所有消息。</p>
<p>下面我们来看下client.send方法
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(ClientRequest request, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    doSend(request, <span class="keyword">false</span>, now);</div><div class="line">&#125;</div><div class="line"><span class="comment">/*.................................................................*/</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doSend</span><span class="params">(ClientRequest clientRequest, <span class="keyword">boolean</span> isInternalRequest, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    String nodeId = clientRequest.destination();</div><div class="line">    <span class="keyword">if</span> (!isInternalRequest) &#123;</div><div class="line">        <span class="keyword">if</span> (!canSendRequest(nodeId))</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Attempt to send a request to node "</span> + nodeId + <span class="string">" which is not ready."</span>);</div><div class="line">    &#125;</div><div class="line">    AbstractRequest request = <span class="keyword">null</span>;</div><div class="line">    AbstractRequest.Builder&lt;?&gt; builder = clientRequest.requestBuilder();</div><div class="line">    </div><div class="line">    request = builder.build();<span class="comment">// builder为ProduceRequest.Builder，request为ProduceRequest</span></div><div class="line"></div><div class="line">    RequestHeader header = clientRequest.makeHeader();</div><div class="line">    <span class="comment">/*..................................................*/</span></div><div class="line">    <span class="comment">// Send是一个接口，这里返回的是NetworkSend，而NetworkSend继承ByteBufferSend</span></div><div class="line">    Send send = request.toSend(nodeId, header);</div><div class="line">    <span class="comment">// 表示正在发送的请求</span></div><div class="line">    InFlightRequest inFlightRequest = <span class="keyword">new</span> InFlightRequest(</div><div class="line">            header,</div><div class="line">            clientRequest.createdTimeMs(),</div><div class="line">            clientRequest.destination(),</div><div class="line">            clientRequest.callback(),</div><div class="line">            clientRequest.expectResponse(),</div><div class="line">            isInternalRequest,</div><div class="line">            send,</div><div class="line">            now);</div><div class="line">    <span class="keyword">this</span>.inFlightRequests.add(inFlightRequest);</div><div class="line">    <span class="comment">//　将send和对应kafkaChannel绑定起来，并开启该kafkaChannel底层socket的写事件</span></div><div class="line">    selector.send(inFlightRequest.send);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>dosend方法内部先是将clientRequest转换为ProduceRequest，然后调用ProduceRequest.toSend方法将消息封装成NetworkSend类型，该类型继承ByteBufferSend，最主要成员有一个size=2的ByteBuffer数组，第一个ByteBuffer存储所有消息的size，另一个ByteBuffer存储所有消息。</p>
<p>在发送请求之前需要把该请求添加到inFlightRequests队列中，表示正在发送还没收到ack的请求，当收到kafka server的ack之后，kafka producer将该消息从inFlightRequest中删除。</p>
<p>最后调用selector.send(inFlightRequest.send)将该NetworkSend与KafkaChannel绑定起来，并为KafkaChannel底层的socket开启可写事件。下面来看下selector.send方法
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(Send send)</span> </span>&#123;</div><div class="line">    String connectionId = send.destination();</div><div class="line">    <span class="keyword">if</span> (closingChannels.containsKey(connectionId))</div><div class="line">        <span class="keyword">this</span>.failedSends.add(connectionId);</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">        KafkaChannel channel = channelOrFail(connectionId, <span class="keyword">false</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            channel.setSend(send);</div><div class="line">        &#125; <span class="keyword">catch</span> (CancelledKeyException e) &#123;</div><div class="line">            <span class="keyword">this</span>.failedSends.add(connectionId);</div><div class="line">            close(channel, <span class="keyword">false</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/*................................................................*/</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSend</span><span class="params">(Send send)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.send != <span class="keyword">null</span>)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Attempt to begin a send operation with prior send operation still in progress."</span>);</div><div class="line">    <span class="keyword">this</span>.send = send;</div><div class="line">    <span class="comment">// 开启可写事件</span></div><div class="line">    <span class="keyword">this</span>.transportLayer.addInterestOps(SelectionKey.OP_WRITE);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>ok，当以上步骤的执行结束时，接下来即可返回到sender线程类的run()方法的sendProduceRequests(batches, now)方法，该方法执行结束，此时为每个broker的kafkaChannel都绑定了各自的NetworkSend。最后调用this.client.poll(pollTimeout, now);方法将消息发送出去。
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    <span class="keyword">long</span> metadataTimeout = metadataUpdater.maybeUpdate(now);</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));</div><div class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">        log.error(<span class="string">"Unexpected error during I/O"</span>, e);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// process completed actions</span></div><div class="line">    <span class="keyword">long</span> updatedNow = <span class="keyword">this</span>.time.milliseconds();</div><div class="line">    List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">    handleAbortedSends(responses);</div><div class="line">    handleCompletedSends(responses, updatedNow);</div><div class="line">    handleCompletedReceives(responses, updatedNow);</div><div class="line">    handleDisconnections(responses, updatedNow);</div><div class="line">    handleConnections();</div><div class="line">    handleInitiateApiVersionRequests(updatedNow);</div><div class="line">    handleTimedOutRequests(responses, updatedNow);</div><div class="line"></div><div class="line">    <span class="comment">// 当收到kafka server的ack时，调用每个请求当时设置的毁掉函数</span></div><div class="line">    <span class="keyword">for</span> (ClientResponse response : responses) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            response.onComplete();</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            log.error(<span class="string">"Uncaught error in request completion:"</span>, e);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> responses;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个函数先是调用selector.poll方法，这个selector是kafka封装java nio的selector，即IO多路复用。selector.poll方法监听到某个broker的KafkaChannel可写时，即可将调用KafkaChannel.write方法，把数据发送给kafka server。如果kafka　server立即返回数据，那么再selector下一次轮询时即可收到kafka server返回的response。因此再selector.poll函数返回时，此时已经完成了socket的读写操作，最后再NetworkClient.poll方法中做最后处理工作。例如handleCompletedSends函数需要把已经发送成功的请求从inFlightRequests列表中删除。</p>
<p>这里需要说明的是，那个for循环执行的回调函数，是从大到小的顺序执行。即先是执行ClientResponse.onComplete方法，然后onComplete函数内部执行sender.handleProduceResponse方法，接着在上述方法内部执行completeBatch方法，最后再completeBatch方法内部执行每条消息的的回调函数。</p>
<p>ok，到这里就把消息的发送过程讲完了，下面看看元数据的更新。</p>
<h2>更新metadata</h2>
<p>KafkaProducer除了发送消息外，还需要不断更新元数据。例如第一次发送消息时，需要先获取TopicPartition对应broker上的连接，然后初始化Cluster信息；　当KafkaProducer发送一个还没识别的Topic时，也需要进行一次metadata更新等等。</p>
<p>下面从第一次更新metadata开始，再KafkaProducer.dosend()方法中的waitOnMetadata函数，如下
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> ClusterAndWaitTime <span class="title">waitOnMetadata</span><span class="params">(String topic, Integer partition, <span class="keyword">long</span> maxWaitMs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">        <span class="comment">// 把topic添加metadata里面的topic列表中</span></div><div class="line">    metadata.add(topic);</div><div class="line">    Cluster cluster = metadata.fetch();</div><div class="line">    Integer partitionsCount = cluster.partitionCountForTopic(topic);</div><div class="line">    <span class="comment">// 如果之前已经获取了该topic的元数据，并缓存再cluster，则直接返回ClusterAndWaitTime实例</span></div><div class="line">    <span class="keyword">if</span> (partitionsCount != <span class="keyword">null</span> &amp;&amp; (partition == <span class="keyword">null</span> || partition &lt; partitionsCount))</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ClusterAndWaitTime(cluster, <span class="number">0</span>);</div><div class="line"></div><div class="line">    <span class="keyword">long</span> begin = time.milliseconds();</div><div class="line">    <span class="keyword">long</span> remainingWaitMs = maxWaitMs;</div><div class="line">    <span class="keyword">long</span> elapsed;</div><div class="line">    <span class="comment">// Issue metadata requests until we have metadata for the topic or maxWaitTimeMs is exceeded.</span></div><div class="line">    <span class="comment">// In case we already have cached metadata for the topic, but the requested partition is greater</span></div><div class="line">    <span class="comment">// than expected, issue an update request only once. This is necessary in case the metadata</span></div><div class="line">    <span class="comment">// is stale and the number of partitions for this topic has increased in the meantime.</span></div><div class="line">    <span class="keyword">do</span> &#123;</div><div class="line">        log.trace(<span class="string">"Requesting metadata update for topic &#123;&#125;."</span>, topic);</div><div class="line">        <span class="keyword">int</span> version = metadata.requestUpdate();</div><div class="line">        sender.wakeup();</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            metadata.awaitUpdate(version, remainingWaitMs);</div><div class="line">        &#125; <span class="keyword">catch</span> (TimeoutException ex) &#123;</div><div class="line">            <span class="comment">// Rethrow with original maxWaitMs to prevent logging exception with remainingWaitMs</span></div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(<span class="string">"Failed to update metadata after "</span> + maxWaitMs + <span class="string">" ms."</span>);</div><div class="line">        &#125;</div><div class="line">        cluster = metadata.fetch();</div><div class="line">        elapsed = time.milliseconds() - begin;</div><div class="line">        <span class="keyword">if</span> (elapsed &gt;= maxWaitMs)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(<span class="string">"Failed to update metadata after "</span> + maxWaitMs + <span class="string">" ms."</span>);</div><div class="line">        <span class="keyword">if</span> (cluster.unauthorizedTopics().contains(topic))</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TopicAuthorizationException(topic);</div><div class="line">        remainingWaitMs = maxWaitMs - elapsed;</div><div class="line">        partitionsCount = cluster.partitionCountForTopic(topic);</div><div class="line">    &#125; <span class="keyword">while</span> (partitionsCount == <span class="keyword">null</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (partition != <span class="keyword">null</span> &amp;&amp; partition &gt;= partitionsCount) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(</div><div class="line">                String.format(<span class="string">"Invalid partition given with record: %d is not in the range [0...%d)."</span>, partition, partitionsCount));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ClusterAndWaitTime(cluster, elapsed);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>该函数时在KafkaProducer线程中，因此如果metadata没有被更新的话，则一直处于while循环中。再do...wwhile循环内部，</p>
<ol>
<li>一开始调用metadata.requestUpdata()，设置this.needUpdate = true，并返回当前版本号。</li>
<li>然后调用sender.wakeup唤醒sender线程。</li>
<li>metadata.awaitUpdate(version, remainingWaitMs)等待更新。</li>
</ol>
<p>我们来看下metadata.awaitUpdate方法
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">awaitUpdate</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> lastVersion, <span class="keyword">final</span> <span class="keyword">long</span> maxWaitMs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (maxWaitMs &lt; <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Max time to wait for metadata updates should not be &lt; 0 milli seconds"</span>);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">long</span> begin = System.currentTimeMillis();</div><div class="line">    <span class="keyword">long</span> remainingWaitMs = maxWaitMs;</div><div class="line">    <span class="keyword">while</span> (<span class="keyword">this</span>.version &lt;= lastVersion) &#123;</div><div class="line">        <span class="keyword">if</span> (remainingWaitMs != <span class="number">0</span>)</div><div class="line">            wait(remainingWaitMs);</div><div class="line">        <span class="keyword">long</span> elapsed = System.currentTimeMillis() - begin;</div><div class="line">        <span class="keyword">if</span> (elapsed &gt;= maxWaitMs)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(<span class="string">"Failed to update metadata after "</span> + maxWaitMs + <span class="string">" ms."</span>);</div><div class="line">        remainingWaitMs = maxWaitMs - elapsed;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>该函数会阻塞再while循环中，即当前版本小于等于最后一次更新的版本。因此此时KafkaProducer会阻塞再两个while循环中。</p>
<ul>
<li>waitOnMetadata方法中的do...while循环，等待获取topic的partition数不为０</li>
<li>awaitUpdate方法中的while循环，等待版本更新。</li>
</ul>
<p>那么在哪更新这个版本了，当然不用想，肯定是在sender函数，因为此时KafkaProducer已经阻塞了。我们可以发现在NetworkClient的poll函数中有如下调用
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    <span class="keyword">long</span> metadataTimeout = metadataUpdater.maybeUpdate(now);</div><div class="line">    <span class="comment">//.....................</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>因此我们可以知道在任何一次发送数据之前都会进行一次判断元数据是否需要更新， 接下来我们看下metadataUpdater.maybeUpdate(now),
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">maybeUpdate</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</div><div class="line">    <span class="comment">// 判断metadata是否需要更新，主要是通过metadataTimeout和requestTimeoutMs进行判断</span></div><div class="line">    <span class="comment">//　即metadata超时时间和请求超时时间</span></div><div class="line">    <span class="keyword">long</span> timeToNextMetadataUpdate = metadata.timeToNextUpdate(now);</div><div class="line">    <span class="keyword">long</span> waitForMetadataFetch = <span class="keyword">this</span>.metadataFetchInProgress ? requestTimeoutMs : <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">long</span> metadataTimeout = Math.max(timeToNextMetadataUpdate, waitForMetadataFetch);</div><div class="line">    <span class="keyword">if</span> (metadataTimeout &gt; <span class="number">0</span>) &#123;</div><div class="line">        <span class="keyword">return</span> metadataTimeout;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 选择一个负载最小的KafkaServer更新metadata</span></div><div class="line">    Node node = leastLoadedNode(now);</div><div class="line">    <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</div><div class="line">        log.debug(<span class="string">"Give up sending metadata request since no node is available"</span>);</div><div class="line">        <span class="keyword">return</span> reconnectBackoffMs;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> maybeUpdate(now, node);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个函数，timeToNextMetadataUpdate变量为metadata需要更新的下一个时间；如果已经发送metadataFetchRequest，则waitForMetadataFetch为请求的超时时间，否则为0。如果上述两个值最大值大于0，则还没到更新metadata的时间，直接返回更新时间。</p>
<p>如果需要更新，则先是获取一个负载最小的kafkaServer，然后执行metadata更新，下面这个时metadata更新最终的函数
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">maybeUpdate</span><span class="params">(<span class="keyword">long</span> now, Node node)</span> </span>&#123;</div><div class="line">    String nodeConnectionId = node.idString();</div><div class="line">    <span class="comment">//　如果该节点可以发送请求，则发送metadataRequest</span></div><div class="line">    <span class="keyword">if</span> (canSendRequest(nodeConnectionId)) &#123;</div><div class="line">        <span class="keyword">this</span>.metadataFetchInProgress = <span class="keyword">true</span>;</div><div class="line">        MetadataRequest.Builder metadataRequest;</div><div class="line">        <span class="keyword">if</span> (metadata.needMetadataForAllTopics())</div><div class="line">            metadataRequest = MetadataRequest.Builder.allTopics();</div><div class="line">        <span class="keyword">else</span></div><div class="line">            metadataRequest = <span class="keyword">new</span> MetadataRequest.Builder(<span class="keyword">new</span> ArrayList&lt;&gt;(metadata.topics()));</div><div class="line"></div><div class="line"></div><div class="line">        log.debug(<span class="string">"Sending metadata request &#123;&#125; to node &#123;&#125;"</span>, metadataRequest, node.id());</div><div class="line">        sendInternalMetadataRequest(metadataRequest, nodeConnectionId, now);</div><div class="line">        <span class="keyword">return</span> requestTimeoutMs;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 如果正在与broker建立连接，则返回重连接延迟时间.</span></div><div class="line">    <span class="keyword">if</span> (isAnyNodeConnecting()) &#123;</div><div class="line">        <span class="keyword">return</span> reconnectBackoffMs;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (connectionStates.canConnect(nodeConnectionId, now)) &#123;</div><div class="line">        <span class="comment">// 如果node还没建立连接，则建立连接</span></div><div class="line">        log.debug(<span class="string">"Initialize connection to node &#123;&#125; for sending metadata request"</span>, node.id());</div><div class="line">        initiateConnect(node, now);</div><div class="line">        <span class="keyword">return</span> reconnectBackoffMs;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// connected, but can't send more OR connecting</span></div><div class="line">    <span class="comment">// In either case, we just need to wait for a network event to let us know the selected</span></div><div class="line">    <span class="comment">// connection might be usable again.</span></div><div class="line">    <span class="keyword">return</span> Long.MAX_VALUE;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>因此每次metadata更新时有三种情况</p>
<ol>
<li>如果节点可以发送请求，则直接发送请求。判断是否可以发送请求包括是否已经建立连接，发往该broker的请求是否太多，即负载过大。</li>
<li>如果正在建立连接，则返回。</li>
<li>如果还没建立连接，则向broker发起连接。</li>
</ol>
<p>而我们知道KafkaProducer之前阻塞在metadata版本更新上，因此sender线程</p>
<ol>
<li>第一次轮询返回时，建立到broker的连接。</li>
<li>第二次轮询返回时，发送metadataFetch请求。</li>
<li>第三次轮询返回时，获取metadataResponse，并更新metadata。
经过上述sender线程三次轮询，metadata得到更新，此时KafkaProducer不再阻塞，开始发送消息数据。</li>
</ol>
<p>metadata再两种情况下会进行更新，一种是像KafkaProducer第一次发送消息时强制更新，另一次是周期进行更新。当然代码中不止KafkaProducer第一次发送消息时强制更新数据，例如当发现有broker宕机时也会更新一次metadata等等。</p>
<h1>总结</h1>
<hr>
<p>大概把KafkaProducer大体介绍完毕，KafkaProducer主要分为三个部分，一个数Producer主线程发送数据，一个是sender线程真正发送数据以及更新metadata。下篇文章说说KafkaConsumer。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/kafka/" rel="tag">#kafka</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/04/24/kafka01/" rel="next" title="kafka源码分析之概述">
                <i class="fa fa-chevron-left"></i> kafka源码分析之概述
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


<div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div>
<script src="https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js"></script>
<script>
var cloudTieConfig = {
  url: document.location.href,
  sourceId: "",
  productKey: "5f86fe3bc07e4e31adb4a20c48cbf8f2",
  target: "cloud-tie-wrapper"
};
var yunManualLoad = true;
Tie.loader("aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s", true);
</script>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/psb.jpg"
               alt="罗道文" />
          <p class="site-author-name" itemprop="name">罗道文</p>
          <p class="site-description motion-element" itemprop="description">分享知识，分享快乐</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">106</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">33</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">116</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/luodw" target="_blank" title="github">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  github
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/1699355617/profile?rightmod=1&wvr=6&mod=personinfo" target="_blank" title="weibo">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.zhihu.com/people/tao-tao-tao-tao-wen" target="_blank" title="zhihu">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  zhihu
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-block">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://mingxinglai.com/" title="赖明星的博客地址" target="_blank">赖明星的博客地址</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.powerxing.com/" title="蔡珉星的博客地址" target="_blank">蔡珉星的博客地址</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://nekomiao.me/" title="阮榕城的博客地址" target="_blank">阮榕城的博客地址</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://youbingchenyoubing.leanote.com/" title="陈友兵的博客地址" target="_blank">陈友兵的博客地址</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://zhengjianglong.leanote.com/" title="郑江龙的博客地址" target="_blank">郑江龙的博客地址</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://dblab.xmu.edu.cn/" title="厦门大学数据库实验室" target="_blank">厦门大学数据库实验室</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text">Kafka Producer使用介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">Kafka Producer运行原理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">Kafka Producer运行过程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">3.1.</span> <span class="nav-text">Producer发送消息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">3.2.</span> <span class="nav-text">sender线程发送请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-number">3.3.</span> <span class="nav-text">更新metadata</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">罗道文</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次 |
</span>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>




  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = decodeURIComponent(data.url);
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("d4M77Uwmt5bMmtRK3JC3pw6h-gzGzoHsz", "aSDV89NgDrUbl8iqhvmdOiEU");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


</body>
</html>
